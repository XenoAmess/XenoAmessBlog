---
title: 垃圾佬方案搭建llm服务器踩坑经验(持续更新)
date: 2024-09-07 00:00:00
tags: [ '经验' ]
my: XenoAmess

---

### 1. 显卡相关

#### )1

特斯拉系显卡的8pin不是正常显卡的8pin,需要额外购买转接线

(正常8pin * 2 转 特斯拉8pin)

#### )2

vllm已宣称不支持P100. 

mlc-llm能跑,但是效果非常奇怪,疑似量化问题?继续调试. 

llama.cpp一切正常.

#### )3

摩尔线程正在适配S80与llama.cpp的对接.并且下一步的计划单包含vllm.可以加入观望.(更新: 摩尔官方的干员号称已经完成了llama.cpp和ollama对接,就等下次驱动和musa开发包更新了.继续观望.)

S3000是已经支持的,但是S30000只随数据中心一起出售.toB的,个人很难获取.还是继续等S80吧

### 2. 内存相关

#### )1

服务器往往必须使用ecc内存, ddr4 ecc内存和ddr4内存虽然卡槽一样,能插进去,但是无法相互换用(反过来也不行) 会报**No memory DIMM detected**错

#### )2

双cpu服务器 内存尽可能对称插.尽量先插蓝色的槽,全插了再考虑黑色的槽

#### )3

ecc内存 黄鱼和其他渠道的价格差距非常大,并且黄鱼货并没有显著质量问题.无条件请尽可能走黄鱼.

20250421更新: 黄鱼的6条内存坏了一条,寄.

今后使用了黄鱼的内存, 出现开机几分钟后突然卡住, 第一时间怀疑内存问题.

使用stress工具进行内存分配压测, 以实锤内存问题.

```shell
stress --vm 1 --vm-bytes 100G
```


### 3. 服务器相关

#### )1

4028-gr-tr2是一台非常吵的机器.请自备听力保护设备.(推荐静音耳罩,3M的效果可以)

吵的主要原因是风扇(废话).风道设计非常~~简陋~~古早,如果更加合理地设计一下风道或许可以部分解决?存疑,我对风道一窍不通,专业人士或可以自己考量...

#### )2

4028-gr-tr2 中间的4个pcie槽挨得非常近,如果不给显卡物理切割,应该不可能插进去4根...算了,同时插8根还不能满足吗

### 4. 绘图相关

#### )1

不要使用stable-diffusion-webui,缺乏潜力.请直接ComfyUI上手, 学会以后StableSwarmUI套ComfyUI做批量(StableSwarmUI对每个显卡配置启动ComfyUI实例,达到并发).

\# 未来终究ComfyUI这种工作流的.这不禁让我想到,是否对于非会话的llm-chat,也可以基于流程图进行架构设计呢? 似乎是可以的, 流程+代码+外部函数, 逻辑上似乎是符合的...

#### )2

不要试图生成太大的图,尤其是宽大于高的图.stable-diffusion对大图的布局能力有限,会生成多手/多头/残肢怪.如果你想要生成1920\*1080,你实际需要做的是先生成960\*540,再scaling\*2. 对于P100, 这样的配置batch可以设置为3.大于3会overflow显存.

#### )3

LORA在stable-diffusion上的效果是极其显著的...似乎比llm对话上更加显著?存疑,待更多实验.

### 5. 其他

#### )1

vga输出转hdmi线是一个非常操蛋的方案,兼容性很差,如果你的服务器是vga输出那你就老老实实vga输出.

#### )2

如果你没有一个及格的网络环境,可以考虑华为/中兴等的随身wifi. 50-/月的价格就能拿到1000G流量. 比正常手机流量便宜很多.
